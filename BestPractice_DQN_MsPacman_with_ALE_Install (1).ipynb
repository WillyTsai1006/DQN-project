{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1a22f703",
      "metadata": {
        "id": "1a22f703"
      },
      "source": [
        "# 最佳實務版 DQN 訓練（MsPacman）\n",
        "使用：Double DQN、reward clipping、gradient clipping、epsilon 指數衰減、target sync、frame stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "28168e6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28168e6a",
        "outputId": "0f75d8d1-43b4-49e7-e49e-c189d1dcbac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: \"'gym[atari,accept-rom-license]'\": Expected package name at the start of dependency specifier\n",
            "    'gym[atari,accept-rom-license]'\n",
            "    ^\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\tC:\\Users\\waychen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\AutoROM\\roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "✅ MsPacman 環境成功載入，畫面大小： (210, 160, 3)\n"
          ]
        }
      ],
      "source": [
        "# ✅ 自動安裝 ALE + ROM + 測試 MsPacman 是否能載入\n",
        "%pip install 'gym[atari,accept-rom-license]' ale-py AutoROM -q\n",
        "!AutoROM --accept-license\n",
        "import gym\n",
        "env = gym.make('ALE/MsPacman-v5', render_mode='rgb_array')\n",
        "obs, _ = env.reset()\n",
        "print('✅ MsPacman 環境成功載入，畫面大小：', obs.shape)\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6aaad6",
      "metadata": {
        "id": "5c6aaad6"
      },
      "outputs": [],
      "source": [
        "%pip install gym[atari] opencv-python moviepy imageio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "431106f1",
      "metadata": {
        "id": "431106f1"
      },
      "outputs": [],
      "source": [
        "import gym, cv2, random, os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque, namedtuple\n",
        "from gym.wrappers import RecordVideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "02a8dc0c",
      "metadata": {
        "id": "02a8dc0c"
      },
      "outputs": [],
      "source": [
        "# 畫面預處理與 frame stacking\n",
        "def preprocess(obs):\n",
        "    obs = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
        "    obs = cv2.resize(obs, (84, 84))\n",
        "    return obs / 255.0\n",
        "\n",
        "def stack_frames(frames):\n",
        "    return np.stack(frames, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dd06cfee",
      "metadata": {
        "id": "dd06cfee"
      },
      "outputs": [],
      "source": [
        "# DQN 架構\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, 8, 4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, 1), nn.ReLU()\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(3136, 512), nn.ReLU(), nn.Linear(512, num_actions)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8f1b940f",
      "metadata": {
        "id": "8f1b940f"
      },
      "outputs": [],
      "source": [
        "# 記憶體\n",
        "Experience = namedtuple('Experience', ['state', 'action', 'reward', 'next_state', 'done'])\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "    def push(self, *args):\n",
        "        self.buffer.append(Experience(*args))\n",
        "    def sample(self, batch_size):\n",
        "        samples = random.sample(self.buffer, batch_size)\n",
        "        return map(lambda x: torch.tensor(np.array(x)), zip(*samples))\n",
        "    def __len__(self): return len(self.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c8caf96c",
      "metadata": {
        "id": "c8caf96c"
      },
      "outputs": [],
      "source": [
        "# 超參數\n",
        "ENV_NAME = 'ALE/MsPacman-v5'\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 20000\n",
        "MIN_REPLAY_SIZE = 5000\n",
        "EPS_START = 1.0\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 100000\n",
        "LR = 1e-4\n",
        "TARGET_UPDATE_FREQ = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bef0c9a2",
      "metadata": {
        "id": "bef0c9a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\waychen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gym\\wrappers\\record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at d:\\code\\pythoncode\\DQN-project\\videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "# 初始化\n",
        "env = gym.make(ENV_NAME, render_mode='rgb_array')\n",
        "env = RecordVideo(env, video_folder=\"videos\", episode_trigger=lambda e: e % 10 == 0)\n",
        "num_actions = env.action_space.n\n",
        "policy_net = DQN((4,84,84), num_actions).to(device)\n",
        "target_net = DQN((4,84,84), num_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
        "replay_buffer = ReplayBuffer(BUFFER_SIZE)\n",
        "steps_done = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "SUtwI1rCt7Hk",
      "metadata": {
        "id": "SUtwI1rCt7Hk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\waychen\\AppData\\Local\\Temp\\ipykernel_22472\\439357633.py:1: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not hasattr(np, 'bool8'):\n"
          ]
        }
      ],
      "source": [
        "if not hasattr(np, 'bool8'):\n",
        "    np.bool8 = np.bool_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d8b451a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8b451a1",
        "outputId": "a1f9fb46-ba4d-4a74-8d64-e84064bff656"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\waychen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gym\\utils\\passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  logger.warn(\n",
            "C:\\Users\\waychen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-0.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-0.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-0.mp4\n",
            "Episode 1 - Reward: 29.0\n",
            "Episode 2 - Reward: 15.0\n",
            "Episode 3 - Reward: 20.0\n",
            "Episode 4 - Reward: 24.0\n",
            "Episode 5 - Reward: 28.0\n",
            "Episode 6 - Reward: 25.0\n",
            "Episode 7 - Reward: 25.0\n",
            "Episode 8 - Reward: 17.0\n",
            "Episode 9 - Reward: 27.0\n",
            "Episode 10 - Reward: 20.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-10.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-10.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-10.mp4\n",
            "Episode 11 - Reward: 33.0\n",
            "Episode 12 - Reward: 15.0\n",
            "Episode 13 - Reward: 24.0\n",
            "Episode 14 - Reward: 18.0\n",
            "Episode 15 - Reward: 25.0\n",
            "Episode 16 - Reward: 22.0\n",
            "Episode 17 - Reward: 29.0\n",
            "Episode 18 - Reward: 27.0\n",
            "Episode 19 - Reward: 24.0\n",
            "Episode 20 - Reward: 21.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-20.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-20.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-20.mp4\n",
            "Episode 21 - Reward: 62.0\n",
            "Episode 22 - Reward: 26.0\n",
            "Episode 23 - Reward: 15.0\n",
            "Episode 24 - Reward: 36.0\n",
            "Episode 25 - Reward: 15.0\n",
            "Episode 26 - Reward: 34.0\n",
            "Episode 27 - Reward: 19.0\n",
            "Episode 28 - Reward: 23.0\n",
            "Episode 29 - Reward: 18.0\n",
            "Episode 30 - Reward: 18.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-30.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-30.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-30.mp4\n",
            "Episode 31 - Reward: 23.0\n",
            "Episode 32 - Reward: 18.0\n",
            "Episode 33 - Reward: 51.0\n",
            "Episode 34 - Reward: 22.0\n",
            "Episode 35 - Reward: 30.0\n",
            "Episode 36 - Reward: 29.0\n",
            "Episode 37 - Reward: 27.0\n",
            "Episode 38 - Reward: 24.0\n",
            "Episode 39 - Reward: 33.0\n",
            "Episode 40 - Reward: 33.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-40.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-40.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-40.mp4\n",
            "Episode 41 - Reward: 39.0\n",
            "Episode 42 - Reward: 62.0\n",
            "Episode 43 - Reward: 34.0\n",
            "Episode 44 - Reward: 45.0\n",
            "Episode 45 - Reward: 30.0\n",
            "Episode 46 - Reward: 35.0\n",
            "Episode 47 - Reward: 25.0\n",
            "Episode 48 - Reward: 25.0\n",
            "Episode 49 - Reward: 27.0\n",
            "Episode 50 - Reward: 23.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-50.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-50.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-50.mp4\n",
            "Episode 51 - Reward: 29.0\n",
            "Episode 52 - Reward: 36.0\n",
            "Episode 53 - Reward: 39.0\n",
            "Episode 54 - Reward: 30.0\n",
            "Episode 55 - Reward: 26.0\n",
            "Episode 56 - Reward: 30.0\n",
            "Episode 57 - Reward: 33.0\n",
            "Episode 58 - Reward: 38.0\n",
            "Episode 59 - Reward: 20.0\n",
            "Episode 60 - Reward: 21.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-60.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-60.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-60.mp4\n",
            "Episode 61 - Reward: 31.0\n",
            "Episode 62 - Reward: 26.0\n",
            "Episode 63 - Reward: 52.0\n",
            "Episode 64 - Reward: 49.0\n",
            "Episode 65 - Reward: 33.0\n",
            "Episode 66 - Reward: 27.0\n",
            "Episode 67 - Reward: 25.0\n",
            "Episode 68 - Reward: 37.0\n",
            "Episode 69 - Reward: 25.0\n",
            "Episode 70 - Reward: 49.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-70.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-70.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-70.mp4\n",
            "Episode 71 - Reward: 56.0\n",
            "Episode 72 - Reward: 36.0\n",
            "Episode 73 - Reward: 28.0\n",
            "Episode 74 - Reward: 38.0\n",
            "Episode 75 - Reward: 20.0\n",
            "Episode 76 - Reward: 51.0\n",
            "Episode 77 - Reward: 24.0\n",
            "Episode 78 - Reward: 23.0\n",
            "Episode 79 - Reward: 66.0\n",
            "Episode 80 - Reward: 39.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-80.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-80.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-80.mp4\n",
            "Episode 81 - Reward: 29.0\n",
            "Episode 82 - Reward: 35.0\n",
            "Episode 83 - Reward: 60.0\n",
            "Episode 84 - Reward: 22.0\n",
            "Episode 85 - Reward: 41.0\n",
            "Episode 86 - Reward: 40.0\n",
            "Episode 87 - Reward: 85.0\n",
            "Episode 88 - Reward: 33.0\n",
            "Episode 89 - Reward: 85.0\n",
            "Episode 90 - Reward: 17.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-90.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-90.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-90.mp4\n",
            "Episode 91 - Reward: 33.0\n",
            "Episode 92 - Reward: 39.0\n",
            "Episode 93 - Reward: 31.0\n",
            "Episode 94 - Reward: 17.0\n",
            "Episode 95 - Reward: 41.0\n",
            "Episode 96 - Reward: 28.0\n",
            "Episode 97 - Reward: 73.0\n",
            "Episode 98 - Reward: 28.0\n",
            "Episode 99 - Reward: 37.0\n",
            "Episode 100 - Reward: 44.0\n",
            "MoviePy - Building video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-100.mp4.\n",
            "MoviePy - Writing video d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-100.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready d:\\code\\pythoncode\\DQN-project\\videos\\rl-video-episode-100.mp4\n"
          ]
        }
      ],
      "source": [
        "# 訓練主迴圈\n",
        "for episode in range(100):\n",
        "    obs, _ = env.reset()\n",
        "    obs = preprocess(obs)\n",
        "    frames = [obs] * 4\n",
        "    state = stack_frames(frames)\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        epsilon = EPS_END + (EPS_START - EPS_END) * np.exp(-1. * steps_done / EPS_DECAY)\n",
        "        if random.random() < epsilon:\n",
        "            action = random.randrange(num_actions)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "                action = policy_net(state_tensor).argmax(1).item()\n",
        "\n",
        "        next_obs, reward, done, _, _ = env.step(action)\n",
        "        reward = np.clip(reward, -1, 1)\n",
        "        next_obs = preprocess(next_obs)\n",
        "        frames.pop(0); frames.append(next_obs)\n",
        "        next_state = stack_frames(frames)\n",
        "        replay_buffer.push(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        steps_done += 1\n",
        "\n",
        "        if len(replay_buffer) > MIN_REPLAY_SIZE:\n",
        "            states, actions, rewards, next_states, dones = replay_buffer.sample(BATCH_SIZE)\n",
        "            states = states.float().to(device)\n",
        "            actions = actions.long().unsqueeze(1).to(device)\n",
        "            rewards = rewards.float().to(device)\n",
        "            next_states = next_states.float().to(device)\n",
        "            dones = dones.float().to(device)\n",
        "\n",
        "            q_values = policy_net(states).gather(1, actions).squeeze(1)\n",
        "            with torch.no_grad():\n",
        "                next_actions = policy_net(next_states).argmax(1, keepdim=True)\n",
        "                next_q = target_net(next_states).gather(1, next_actions).squeeze(1)\n",
        "                target_q = rewards + GAMMA * next_q * (1 - dones)\n",
        "\n",
        "            loss = nn.MSELoss()(q_values, target_q)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            if steps_done % TARGET_UPDATE_FREQ == 0:\n",
        "                target_net.load_state_dict(policy_net.state_dict())\n",
        "    print(f\"Episode {episode+1} - Reward: {total_reward:.1f}\")\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
